'use strict'

<<<<<<< HEAD
=======
const Buffer = require('./buffer.js')

>>>>>>> d0fe5eddc08ee8cb4170b033d03c0424f4964688
// XXX: This shares a lot in common with extract.js
// maybe some DRY opportunity here?

// tar -t
const hlo = require('./high-level-opt.js')
const Parser = require('./parse.js')
const fs = require('fs')
const fsm = require('fs-minipass')
const path = require('path')
const stripSlash = require('./strip-trailing-slashes.js')

<<<<<<< HEAD
module.exports = (opt_, files, cb) => {
=======
const t = module.exports = (opt_, files, cb) => {
>>>>>>> d0fe5eddc08ee8cb4170b033d03c0424f4964688
  if (typeof opt_ === 'function')
    cb = opt_, files = null, opt_ = {}
  else if (Array.isArray(opt_))
    files = opt_, opt_ = {}

  if (typeof files === 'function')
    cb = files, files = null

  if (!files)
    files = []
  else
    files = Array.from(files)

  const opt = hlo(opt_)

  if (opt.sync && typeof cb === 'function')
    throw new TypeError('callback not supported for sync tar functions')

  if (!opt.file && typeof cb === 'function')
    throw new TypeError('callback only supported with file option')

  if (files.length)
    filesFilter(opt, files)

  if (!opt.noResume)
    onentryFunction(opt)

  return opt.file && opt.sync ? listFileSync(opt)
    : opt.file ? listFile(opt, cb)
    : list(opt)
}

const onentryFunction = opt => {
  const onentry = opt.onentry
  opt.onentry = onentry ? e => {
    onentry(e)
    e.resume()
  } : e => e.resume()
}

// construct a filter that limits the file entries listed
// include child entries if a dir is included
const filesFilter = (opt, files) => {
  const map = new Map(files.map(f => [stripSlash(f), true]))
  const filter = opt.filter

  const mapHas = (file, r) => {
    const root = r || path.parse(file).root || '.'
    const ret = file === root ? false
      : map.has(file) ? map.get(file)
      : mapHas(path.dirname(file), root)

    map.set(file, ret)
    return ret
  }

  opt.filter = filter
    ? (file, entry) => filter(file, entry) && mapHas(stripSlash(file))
    : file => mapHas(stripSlash(file))
}

const listFileSync = opt => {
  const p = list(opt)
  const file = opt.file
  let threw = true
  let fd
  try {
    const stat = fs.statSync(file)
<<<<<<< HEAD
    const readSize = opt.maxReadSize || 16 * 1024 * 1024
    if (stat.size < readSize)
      p.end(fs.readFileSync(file))
    else {
=======
    const readSize = opt.maxReadSize || 16*1024*1024
    if (stat.size < readSize) {
      p.end(fs.readFileSync(file))
    } else {
>>>>>>> d0fe5eddc08ee8cb4170b033d03c0424f4964688
      let pos = 0
      const buf = Buffer.allocUnsafe(readSize)
      fd = fs.openSync(file, 'r')
      while (pos < stat.size) {
<<<<<<< HEAD
        const bytesRead = fs.readSync(fd, buf, 0, readSize, pos)
=======
        let bytesRead = fs.readSync(fd, buf, 0, readSize, pos)
>>>>>>> d0fe5eddc08ee8cb4170b033d03c0424f4964688
        pos += bytesRead
        p.write(buf.slice(0, bytesRead))
      }
      p.end()
    }
    threw = false
  } finally {
<<<<<<< HEAD
    if (threw && fd) {
      try {
        fs.closeSync(fd)
      } catch (er) {}
    }
=======
    if (threw && fd)
      try { fs.closeSync(fd) } catch (er) {}
>>>>>>> d0fe5eddc08ee8cb4170b033d03c0424f4964688
  }
}

const listFile = (opt, cb) => {
  const parse = new Parser(opt)
<<<<<<< HEAD
  const readSize = opt.maxReadSize || 16 * 1024 * 1024
=======
  const readSize = opt.maxReadSize || 16*1024*1024
>>>>>>> d0fe5eddc08ee8cb4170b033d03c0424f4964688

  const file = opt.file
  const p = new Promise((resolve, reject) => {
    parse.on('error', reject)
    parse.on('end', resolve)

    fs.stat(file, (er, stat) => {
      if (er)
        reject(er)
      else {
        const stream = new fsm.ReadStream(file, {
          readSize: readSize,
<<<<<<< HEAD
          size: stat.size,
=======
          size: stat.size
>>>>>>> d0fe5eddc08ee8cb4170b033d03c0424f4964688
        })
        stream.on('error', reject)
        stream.pipe(parse)
      }
    })
  })
  return cb ? p.then(cb, cb) : p
}

const list = opt => new Parser(opt)
